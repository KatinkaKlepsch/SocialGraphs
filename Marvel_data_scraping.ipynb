{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Characters and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character():\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    cmtitle = 'cmtitle=Category:Characters'\n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie(category_name):\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    #cmtitle = 'cmtitle=Category:Characters'.format()\n",
    "    \n",
    "    cmtitle = 'cmtitle=Category:{}'.format(category_name)\n",
    "    #cmtitle = \"\"\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_phase =[\"Phase_One_Movies\", \"Phase_Two_Movies\",\"Phase_Three_Movies\",\"Phase_Four_Movies\"]\n",
    "movie_list = {}\n",
    "for movies in movie_phase:\n",
    "    movie_list[movies]= {'movies': movie(movies), 'Phase': movies}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Phase_One_Movies',\n",
       " 'Phase_Two_Movies',\n",
       " 'Phase_Three_Movies',\n",
       " 'Phase_Four_Movies']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movie_list.keys())\n",
    "Phase_1 = movie(\"Phase_One_Movies\")\n",
    "Phase_2 = movie(\"Phase_Two_Movies\")\n",
    "Phase_3 = movie(\"Phase_Three_Movies\")\n",
    "Phase_4 = movie(\"Phase_Four_Movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get character page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "action = \"action=query\"\n",
    "content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "dataformat =\"format=json\"\n",
    "\n",
    "\n",
    "# list of character names - replacing the space with _ such that one can locate the right title\n",
    "char_names = df_character[\"_name\"]\n",
    "\n",
    "# Looping over every characters name using the same API logic and rexex as above\n",
    "for name in char_names:\n",
    "    #name = char_names[idx]\n",
    "    title = \"titles=\"+name\n",
    "    link = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "    \n",
    "    wikiresponse = requests.get(link)\n",
    "    wikitext = wikiresponse.text\n",
    "    wikijson = json.loads(wikitext)\n",
    "\n",
    "    page_id = list(wikijson[\"query\"][\"pages\"].keys())[0] # The page id for each character\n",
    "    \n",
    "    name = name.replace(\"/\", \"_\")\n",
    "    \n",
    "    if len(wikijson[\"query\"][\"pages\"][page_id]['revisions']) > 1:\n",
    "        print(\"Revisions has more than one entry\")\n",
    "    else:\n",
    "        text = wikijson[\"query\"][\"pages\"][page_id]['revisions'][0]['slots']['main']['*']\n",
    "        with open('marvel_characters/'+name+'.txt', 'w') as f: # save the text for each character in the folder\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary with the raw text\n",
    "So we dont have to lad every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_raw_text = {}\n",
    "\n",
    "name_ = df_character['_name']\n",
    "\n",
    "for name in char_names:\n",
    "    name = name.replace(\"/\", \"_\")\n",
    "    with open('marvel_characters/'+ name +'.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        dict_raw_text[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"marvel_characters_raw_text.pickle\", \"wb\")\n",
    "pickle.dump(dict_raw_text, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
